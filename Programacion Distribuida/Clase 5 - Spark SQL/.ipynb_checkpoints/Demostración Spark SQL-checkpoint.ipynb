{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demostracion Clase 4\n",
    "# Spark SQL\n",
    "\n",
    "## Inicializacion del ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-02T05:22:12.046389Z",
     "start_time": "2020-06-02T05:22:11.764426Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/context.py:220: DeprecationWarning: Support for Python 2 and Python 3 prior to version 3.6 is deprecated as of Spark 3.0. See also the plan for dropping Python 2 support at https://spark.apache.org/news/plan-for-dropping-python-2-support.html.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DemoSparkSql\")\\\n",
    "                 .getOrCreate()\n",
    "\n",
    "# Cargo el dataset\n",
    "df = spark.read.format(\"csv\")\\\n",
    "                .option(\"header\", \"true\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load(\"datos/titanic.csv\")\n",
    "#                 .schema(schema)\\\n",
    "\n",
    "# df = spark.read.csv('datos/titanic_long.csv', header=True, inferSchema=True)\n",
    "df.createOrReplaceTempView(\"titanic\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:33:44.665763Z",
     "start_time": "2020-05-28T19:33:44.427686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(Age)|\n",
      "+--------+\n",
      "|    80.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT MAX(Age) FROM titanic where Sex='male' GROUP BY Sex\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T19:51:54.266533Z",
     "start_time": "2020-05-28T19:51:54.134335Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.69911764705882"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(\"Age is not null\").select(F.avg('Age')).take(1)[0][\"avg(Age)\"]\n",
    "# df.na.fill({'Age': 100}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:20:25.808137Z",
     "start_time": "2020-05-28T18:20:25.513184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(Age)|\n",
      "+--------+\n",
      "|    80.0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.Age).where(df.Sex == 'male').agg(F.max(df.Age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T20:58:31.550116Z",
     "start_time": "2020-05-28T20:58:31.318743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+----+-------+------------------+\n",
      "|_c0|Survived|Pclass|   Sex| Age|   Fare|             Clase|\n",
      "+---+--------+------+------+----+-------+------------------+\n",
      "|  0|       0|     3|  male|22.0|   7.25|              Otro|\n",
      "|  1|       1|     1|female|38.0|71.2833|Pasajero clase 1.a|\n",
      "|  2|       1|     3|female|26.0|  7.925|              Otro|\n",
      "|  3|       1|     1|female|35.0|   53.1|Pasajero clase 1.a|\n",
      "|  4|       0|     3|  male|35.0|   8.05|              Otro|\n",
      "|  5|       0|     3|  male|null| 8.4583|              Otro|\n",
      "|  6|       0|     1|  male|54.0|51.8625|Pasajero clase 1.a|\n",
      "|  7|       0|     3|  male| 2.0| 21.075|              Otro|\n",
      "|  8|       1|     3|female|27.0|11.1333|              Otro|\n",
      "|  9|       1|     2|female|14.0|30.0708|              Otro|\n",
      "| 10|       1|     3|female| 4.0|   16.7|              Otro|\n",
      "| 11|       1|     1|female|58.0|  26.55|Pasajero clase 1.a|\n",
      "| 12|       0|     3|  male|20.0|   8.05|              Otro|\n",
      "| 13|       0|     3|  male|39.0| 31.275|              Otro|\n",
      "| 14|       0|     3|female|14.0| 7.8542|              Otro|\n",
      "| 15|       1|     2|female|55.0|   16.0|              Otro|\n",
      "| 16|       0|     3|  male| 2.0| 29.125|              Otro|\n",
      "| 17|       1|     2|  male|null|   13.0|              Otro|\n",
      "| 18|       0|     3|female|31.0|   18.0|              Otro|\n",
      "| 19|       1|     3|female|null|  7.225|              Otro|\n",
      "+---+--------+------+------+----+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"Clase\", F.when(df.Pclass == 1, \"Pasajero clase 1.a\").otherwise('Otro')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:21:38.689651Z",
     "start_time": "2020-05-28T18:21:38.558538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Fare: double, Pclass: int, cuenta: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupBy(df.Fare, df.Pclass).agg( F.count(\"*\").alias(\"cuenta\") )\\\n",
    "    .orderBy(\"cuenta\", ascending=False).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T15:10:40.049914Z",
     "start_time": "2020-05-28T15:10:39.917643Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+\n",
      "| Sex| max|\n",
      "+----+----+\n",
      "|male|80.0|\n",
      "+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"titanic\")\n",
    "spark.sql(\"\"\"\n",
    "SELECT Sex, max(Age) as max\n",
    "FROM titanic where Sex='male'\n",
    "GROUP BY Sex\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:22:24.203567Z",
     "start_time": "2020-05-28T18:22:24.017787Z"
    }
   },
   "outputs": [],
   "source": [
    "q1 = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        Fare,\n",
    "        Pclass,\n",
    "        COUNT(*) as cuenta\n",
    "    FROM titanic\n",
    "    GROUP BY\n",
    "        Fare, Pclass\n",
    "    ORDER BY\n",
    "        cuenta DESC\n",
    "    LIMIT 10\n",
    "    \"\"\")\n",
    "\n",
    "q2 = df.groupBy(df.Fare, df.Pclass).agg(F.count(\"*\").alias(\"cuenta\"))\\\n",
    "    .orderBy(\"cuenta\", ascending=False).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:23:00.339165Z",
     "start_time": "2020-05-28T18:23:00.115575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=10, orderBy=[cuenta#139L DESC NULLS LAST], output=[Fare#21,Pclass#18,cuenta#139L])\n",
      "+- *(2) HashAggregate(keys=[Fare#21, Pclass#18], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(Fare#21, Pclass#18, 200), true, [id=#176]\n",
      "      +- *(1) HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(Fare#21)) AS Fare#21, Pclass#18], functions=[partial_count(1)])\n",
      "         +- FileScan csv [Pclass#18,Fare#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/DiploUTN/datos/titanic.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Pclass:int,Fare:double>\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=10, orderBy=[cuenta#152L DESC NULLS LAST], output=[Fare#21,Pclass#18,cuenta#152L])\n",
      "+- *(2) HashAggregate(keys=[Fare#21, Pclass#18], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(Fare#21, Pclass#18, 200), true, [id=#200]\n",
      "      +- *(1) HashAggregate(keys=[knownfloatingpointnormalized(normalizenanandzero(Fare#21)) AS Fare#21, Pclass#18], functions=[partial_count(1)])\n",
      "         +- FileScan csv [Pclass#18,Fare#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/DiploUTN/datos/titanic.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Pclass:int,Fare:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q1.explain()\n",
    "q2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T13:42:27.560730Z",
     "start_time": "2020-05-28T13:42:26.962530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "891\n"
     ]
    }
   ],
   "source": [
    "print(df.count())\n",
    "print(df.dropDuplicates().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T13:44:27.659994Z",
     "start_time": "2020-05-28T13:44:27.441300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|Survived|Pclass|\n",
      "+--------+------+\n",
      "|       0|     3|\n",
      "|       1|     1|\n",
      "|       1|     3|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"Survived\"], df[\"Pclass\"]).limit(3).show()#take(3)\n",
    "# df.select( \"Sex\", \"Age\").take(1)\n",
    "# df.select(F.when(df.Sex.startswith('fem'), 'Mujer').otherwise('Hombre').alias('Sexo')).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T13:46:14.480574Z",
     "start_time": "2020-05-28T13:46:14.331572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+----+-------+-------+\n",
      "|_c0|Survived|Pclass|   Sex| Age|   Fare|control|\n",
      "+---+--------+------+------+----+-------+-------+\n",
      "|  0|       0|     3|  male|22.0|   7.25|  false|\n",
      "|  1|       1|     1|female|38.0|71.2833|   true|\n",
      "+---+--------+------+------+----+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.selectExpr(\"avg(Age)\", \"count(distinct(Age))\", \"count(*) as cantPasajeros\").show(2)\n",
    "\n",
    "df.withColumn(\"control\", F.expr(\"Survived == Pclass\"))\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+------+----+-----+\n",
      "|_c0|Survived|Pclass|   Sex| Age| Fare|\n",
      "+---+--------+------+------+----+-----+\n",
      "|  0|       0|     3|  male|22.0| 7.25|\n",
      "|  2|       1|     3|female|26.0|7.925|\n",
      "+---+--------+------+------+----+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"Age < 30\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T03:29:22.312059Z",
     "start_time": "2020-05-28T03:29:22.279795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "FileScan csv [_c0#16,Survived#17,Pclass#18,Sex#19,Age#20,Fare#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/DiploUTN/datos/titanic.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<_c0:int,Survived:int,Pclass:int,Sex:string,Age:double,Fare:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:27:11.362340Z",
     "start_time": "2020-05-28T18:27:09.180660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|Survived|Pclass|count|\n",
      "+--------+------+-----+\n",
      "|    null|  null|  891|\n",
      "|    null|     1|  216|\n",
      "|    null|     2|  184|\n",
      "|    null|     3|  491|\n",
      "|       0|  null|  549|\n",
      "|       0|     1|   80|\n",
      "|       0|     2|   97|\n",
      "|       0|     3|  372|\n",
      "|       1|  null|  342|\n",
      "|       1|     1|  136|\n",
      "|       1|     2|   87|\n",
      "|       1|     3|  119|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.cube(\"Survived\", \"Pclass\").count().orderBy(\"Survived\", \"Pclass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:28:47.260369Z",
     "start_time": "2020-05-28T18:28:46.146301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----+\n",
      "|Survived|Pclass|count|\n",
      "+--------+------+-----+\n",
      "|    null|  null|  891|\n",
      "|       0|  null|  549|\n",
      "|       0|     1|   80|\n",
      "|       0|     2|   97|\n",
      "|       0|     3|  372|\n",
      "|       1|  null|  342|\n",
      "|       1|     1|  136|\n",
      "|       1|     2|   87|\n",
      "|       1|     3|  119|\n",
      "+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rollup(\"Survived\",\"Pclass\").count().orderBy(\"Survived\", \"Pclass\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:37:06.044178Z",
     "start_time": "2020-05-28T18:37:06.005156Z"
    }
   },
   "outputs": [],
   "source": [
    "q4 = spark.sql(\"\"\"SELECT\n",
    "                Pclass,\n",
    "                Fare,\n",
    "                Survived,\n",
    "                COUNT(Survived) OVER (PARTITION BY Pclass, Survived ORDER BY Pclass DESC) as cant_survive\n",
    "            FROM\n",
    "                titanic\n",
    "            LIMIT\n",
    "                10\n",
    "          \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:34:33.233683Z",
     "start_time": "2020-05-28T18:34:32.897495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+-------------+\n",
      "|Pclass|   Fare|Survived|cant_survived|\n",
      "+------+-------+--------+-------------+\n",
      "|     1|51.8625|       0|           80|\n",
      "|     1|  263.0|       0|           80|\n",
      "|     1|27.7208|       0|           80|\n",
      "|     1|82.1708|       0|           80|\n",
      "|     1|   52.0|       0|           80|\n",
      "|     1|61.9792|       0|           80|\n",
      "|     1| 83.475|       0|           80|\n",
      "|     1|27.7208|       0|           80|\n",
      "|     1|   47.1|       0|           80|\n",
      "|     1| 61.175|       0|           80|\n",
      "+------+-------+--------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "windowSpec = \\\n",
    "  Window\\\n",
    "    .partitionBy(df['Pclass'], df['Survived']) \\\n",
    "    .orderBy(df['Pclass'].desc())\n",
    "    \n",
    "q3 = df.select(df.Pclass, df.Fare, df.Survived,\n",
    "               F.count(df.Survived).over(windowSpec).alias(\"cant_survived\")).limit(10)\n",
    "\n",
    "q3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:34:57.821092Z",
     "start_time": "2020-05-28T18:34:57.797999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "CollectLimit 10\n",
      "+- Window [count(Survived#17) windowspecdefinition(Pclass#18, Survived#17, Pclass#18 DESC NULLS LAST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS cant_survived#348L], [Pclass#18, Survived#17], [Pclass#18 DESC NULLS LAST]\n",
      "   +- *(2) Sort [Pclass#18 ASC NULLS FIRST, Survived#17 ASC NULLS FIRST, Pclass#18 DESC NULLS LAST], false, 0\n",
      "      +- Exchange hashpartitioning(Pclass#18, Survived#17, 200), true, [id=#447]\n",
      "         +- *(1) Project [Pclass#18, Fare#21, Survived#17]\n",
      "            +- FileScan csv [Survived#17,Pclass#18,Fare#21] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/work/DiploUTN/datos/titanic.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Survived:int,Pclass:int,Fare:double>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q3.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T18:37:10.336251Z",
     "start_time": "2020-05-28T18:37:10.002736Z"
    }
   },
   "outputs": [],
   "source": [
    "q4.write.mode(\"overwrite\").option(\"header\",\"true\").save(\"datos/example\", format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T14:04:19.191796Z",
     "start_time": "2020-05-28T14:04:18.888239Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+--------+------------+\n",
      "|Pclass|   Fare|Survived|cant_survive|\n",
      "+------+-------+--------+------------+\n",
      "|     1|51.8625|       0|          80|\n",
      "|     1|  263.0|       0|          80|\n",
      "|     1|27.7208|       0|          80|\n",
      "|     1|82.1708|       0|          80|\n",
      "|     1|   52.0|       0|          80|\n",
      "|     1|61.9792|       0|          80|\n",
      "|     1| 83.475|       0|          80|\n",
      "|     1|27.7208|       0|          80|\n",
      "|     1|   47.1|       0|          80|\n",
      "|     1| 61.175|       0|          80|\n",
      "+------+-------+--------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('csv').option(\"header\", \"true\")\\\n",
    "                .option(\"inferSchema\", \"true\")\\\n",
    "                .load('datos/example').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
